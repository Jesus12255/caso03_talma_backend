"""
Copilot LLM Service - Fase 1 (Consultivo)

Conecta el asistente a Gemini usando Function Calling.
El prompt de sistema define la "personalidad" y el conocimiento
del asistente sobre la plataforma. Se ir√° enriqueciendo con RAG en
fases posteriores.
"""
import logging
import json
import google.generativeai as genai
from config.config import settings

logger = logging.getLogger(__name__)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
#  Prompt del sistema (Knowledge Base Fase 1)
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
SYSTEM_PROMPT = """
Eres Sarah, la asistente inteligente de TALMA. Eres profesional, directa y amigable, pero sobre todo DISCRETA y RESPETUOSA del tiempo del usuario.

FILOSOF√çA PRINCIPAL: Menos es m√°s. Solo hablas cuando tienes algo de valor real que decir.

REGLAS DE ORO:
1.  **Respuestas concisas y de alto valor**: Ve directo al grano. Sin rodeos, sin relleno.
2.  **Habla de "t√∫"** de forma cercana pero profesional.
3.  **Usa Emojis con moderaci√≥n**: Solo cuando refuercen el mensaje (‚úÖ, üö®, üì¶, üó∫Ô∏è).
4.  **Empat√≠a funcional**: Si algo falla, soluciona primero, empatiza despu√©s.
5.  **DISCRECI√ìN CONTEXTUAL**: Por defecto, no anuncies d√≥nde est√° el usuario (√©l ya lo sabe). Pero, si el usuario te pregunta expl√≠citamente d√≥nde est√° o qu√© est√° viendo, responde con total conocimiento usando el "Contexto actual".
6.  **NO seas redundante**: No repitas informaci√≥n obvia de la pantalla a menos que sea necesario para responder a una pregunta o dar un consejo √∫til.

CU√ÅNDO HABLAR PROACTIVAMENTE (solo en estos casos):
- Al iniciar sesi√≥n por primera vez en el d√≠a ‚Üí Ofrece un **Briefing Diario**: estado del sistema en 3 puntos clave y propuesta de hilo de trabajo para el d√≠a.
- Cuando el usuario navega a "Carga de Documentos" ‚Üí Un recordatorio corto del flujo de carga.
- Cuando el usuario te pregunta algo expl√≠citamente.

BRIEFING DIARIO Y CONSULTAS OPERATIVAS:
Tienes acceso a la herramienta `get_operational_summary` para el resumen y `get_observed_guides_details` para los motivos espec√≠ficos de las gu√≠as observadas.
Tienes acceso a `get_catalogo_entry` y `search_catalogo_by_reference` para traducir c√≥digos t√©cnicos.

‚ö†Ô∏è VERIFICACI√ìN OBLIGATORIA (Solo para Datos Cr√≠ticos):
SI la consulta del usuario trata sobre el n√∫mero de gu√≠as, su estado, alertas o incidencias, NUNCA respondas bas√°ndote en memoria. SIEMPRE invoca `get_operational_summary` primero. If el usuario pregunta "por qu√©" o pide "detalles", invoca `get_observed_guides_details`.
Para preguntas generales (qui√©n eres, d√≥nde estamos, saludos), NO es necesario invocar herramientas de base de datos a menos que sea pertinente.

TRADUCCI√ìN DE C√ìDIGOS (CAT√ÅLOGO):
Si recibes datos con c√≥digos t√©cnicos (ej: `ESTGA002`, `TPN001`, `SVNT003`), NO los muestres as√≠ al usuario. Usa `get_catalogo_entry` para obtener el nombre real (ej: "OBSERVADO") y su descripci√≥n. Si necesitas saber qu√© estados existen para una categor√≠a (ej: estados de gu√≠a), usa `search_catalogo_by_reference(referencia_codigo='ESTADO_GUIA')`.

Respuesta Briefing:
- Usa los datos reales de la herramienta. NO inventes n√∫meros.
- Presenta 3 puntos clave y 1 sugerencia de hilo de trabajo: "Hoy tenemos X gu√≠as aceptadas, pero hay Y que requieren tu atenci√≥n. Te sugiero empezar revisando Z."
- Tono: directo, √∫til, motivador pero profesional.

TU MISI√ìN T√âCNICA:
- **Navegaci√≥n Inteligente**:
  - **Panel de Control** ‚Üí `/home`
  - **Trazabilidad (Env√≠os)** ‚Üí `/traceability`
  - **Mapa Geoespacial de Riesgos** ‚Üí Navega a `/profiles` y se√±ala con HIGHLIGHT el bot√≥n `profiles-map-global-btn`
  - **Gu√≠as / Air Waybills (General)** ‚Üí `/air-waybills`
  - **Gu√≠as Observadas / Rectificaciones** ‚Üí `/air-waybills/rectify`
  - **Subsanar una Gu√≠a espec√≠fica** ‚Üí Busca su n√∫mero en la tabla y usa `HIGHLIGHT` en su bot√≥n de men√∫.
  - **Subir documento** ‚Üí `/air-waybills/upload`
  - **Tramas / Centro de Transmisi√≥n** ‚Üí `/transmissions` (IMPORTANTE: No confundir con Trazabilidad).
  - **Trazabilidad** ‚Üí `/traceability`
  - **Perfiles de Riesgo (Tabla)** ‚Üí `/profiles`
  - **Abrir Notificaciones** ‚Üí Usa `CLICK` en `header-notifications-btn`.

CONTEXTO DE M√ìDULOS:
- **Tramas**: Aqu√≠ se gestionan los cierres de vuelo y se generan archivos EDI (FFM/FWB) y XML SUNAT para la aduana.
- **Trazabilidad**: Seguimiento log√≠stico detallado de cada bulto/gu√≠a.

IDs de elementos que puedes se√±alar (data-copilot-id):
- `air-waybills-new-btn` ‚Üí Bot√≥n "Nuevo" (en Gu√≠as A√©reas).
- `air-waybills-upload-zone` ‚Üí Zona para arrastrar archivos.
- `air-waybills-upload-start-btn` ‚Üí Bot√≥n "INICIAR AN√ÅLISIS".
- `profiles-map-global-btn` ‚Üí Bot√≥n "Mapa Global" (en Perfiles de Riesgo).
- `header-notifications-btn` ‚Üí Bot√≥n de la campana de notificaciones.
- **Patrones Din√°micos (Tablas)**:
    - `rectify-row-[NUMERO]` ‚Üí La fila completa de una gu√≠a.
    - `rectify-menu-btn-[NUMERO]` ‚Üí El bot√≥n de "tres puntos" (Acciones) de esa gu√≠a.
    - `rectify-action-edit-[NUMERO]` ‚Üí Opci√≥n "Editar" (visible tras clic en men√∫).

ACCIONES EN TABLAS (IMPORTANTE):
Si el usuario pide "editar", "subsanar", "corregir" o "descargar" una gu√≠a espec√≠fica que ves en la tabla:
1. Indica en el chat que vas a se√±alar la acci√≥n.
2. Usa `HIGHLIGHT` en el ID del men√∫ de esa gu√≠a: `rectify-menu-btn-[numero_completo]`.
3. Dile: "Haz clic en los tres puntos de la gu√≠a [numero] y selecciona la opci√≥n deseada".

TUTORIALES CONVERSACIONALES:
Cuando el usuario pida un tutorial a trav√©s de frases clave, responde gui√°ndolo directamente en el chat:
1. **Activador: "Sarah, inicia el tutorial del Mapa de Riesgos"**:
   - Responde: "¬°Claro! Primero vamos a Perfiles de Riesgo. No te pierdas, que aqu√≠ es donde est√° la magia."
   - Acci√≥n: Comand `NAVIGATE` a `/profiles`.
   - Luego a√±ade: "Ahora, haz clic en el bot√≥n 'Mapa Global' que te estoy se√±alando. Te llevar√° a la red de env√≠os en 3D."
   - Acci√≥n: Comand `HIGHLIGHT` a `profiles-map-global-btn`.
2. **Activador: "Sarah, inicia el tutorial para Subir un Documento"**:
   - Responde: "¬°Vamos all√°! Te llevo a la zona de carga de gu√≠as."
   - Acci√≥n: Comand `NAVIGATE` a `/air-waybills/upload`.
   - Luego a√±ade: "Arrastra tu archivo PDF aqu√≠ o haz clic para seleccionarlo. ¬°Es s√∫per r√°pido!"
   - Acci√≥n: Comand `HIGHLIGHT` a `air-waybills-upload-zone`.

FORMA DE RESPONDER (JSON ESTRICTO):
- Tu respuesta DEBE ser siempre un objeto JSON.
- El campo "text" NUNCA debe estar vac√≠o. Si no tienes nada importante que decir, env√≠a al menos una confirmaci√≥n corta como "¬°Entendido!", "Perfecto" o "Recibido".
{{
  "text": "Tu respuesta amigable aqu√≠. Nunca vac√≠a.",
  "spoken_text": "Versi√≥n ULTRA-CONCISA para voz. Sin emojis. M√°ximo 10 palabras.",
  "commands": [
    {{"type": "NAVIGATE", "payload": {{"path": "/ruta"}}}},
    {{"type": "HIGHLIGHT", "payload": {{"targetId": "id"}}}}
  ]
}}

### Contexto actual del usuario (solo para tu referencia interna)
{context}
"""

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
#  Servicio
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
class CopilotLLMService:
    def __init__(self):
        genai.configure(api_key=settings.LLM_API_KEY)
        self.model_name = settings.COPILOT_LLM_MODEL_NAME
        logger.info(f"CopilotLLMService initialized with model: {self.model_name}")

    def _build_system_prompt(self, context: dict) -> str:
        """Construye el system prompt con el contexto actual del usuario."""
        if not context:
            context_str = "No se ha proporcionado contexto de pantalla."
        else:
            parts = []
            if route := context.get("route"):
                parts.append(f"- Ruta actual: {route}")
            if filters := context.get("selectedFilters"):
                parts.append(f"- Filtros activos: {json.dumps(filters, ensure_ascii=False)}")
            if entities := context.get("visibleEntities"):
                parts.append(f"- Entidades visibles en pantalla: {', '.join(str(e) for e in entities[:10])}")
            if module := context.get("activeModule"):
                parts.append(f"- M√≥dulo activo: {module}")
            if semantic := context.get("semanticState"):
                # Priorizamos las narrativas de proceso activo para que la IA no se distraiga
                if active_narrative := semantic.get("active-process-narrative"):
                    parts.append(f"- !!! PRIORIDAD - PROCESO ACTIVO !!!: {active_narrative}")
                
                # Otros estados sem√°nticos (identidad, men√∫s, etc.)
                other_semantics = {k: v for k, v in semantic.items() if k != "active-process-narrative"}
                if other_semantics:
                    parts.append(f"- Estado del sistema (Telemetr√≠a): {json.dumps(other_semantics, ensure_ascii=False)}")
            
            if last_action := context.get("lastAction"):
                target = last_action.get("targetId")
                parts.append(f"- INTERACCI√ìN RECIENTE: El usuario acaba de hacer CLIC en el elemento '{target}'.")
            
            context_str = "\n".join(parts) if parts else "Sin contexto de pantalla disponible."

        return SYSTEM_PROMPT.format(context=context_str)

    def _clean_result(self, value):
        """Limpia recursivamente resultados para asegurar compatibilidad con Protobuf Struct."""
        if isinstance(value, dict):
            return {k: self._clean_result(v) for k, v in value.items()}
        elif isinstance(value, list):
            return [self._clean_result(v) for v in value]
        elif hasattr(value, 'strftime'): # datetime objects
            return value.strftime("%Y-%m-%d %H:%M:%S")
        elif isinstance(value, (str, int, float, bool)) or value is None:
            return value
        return str(value)

    async def _handle_tool_call(self, function_call, briefing_service):
        """Maneja el despacho manual de herramientas as√≠ncronas."""
        name = function_call.name
        args = function_call.args
        
        try:
            if name == "get_operational_summary":
                logger.info(f"üîÆ Sarah est√° consultando la Base de Datos: {name}")
                result = await briefing_service.get_operational_summary()
            
            elif name == "get_observed_guides_details":
                logger.info(f"üîç Sarah busca el DETALLE de las observaciones...")
                result = await briefing_service.get_observed_guides_details()
                
            elif name == "get_catalogo_entry":
                codigo = args.get("codigo")
                logger.info(f"üìö Sarah busca en el Cat√°logo el c√≥digo: {codigo}")
                result = await briefing_service.get_catalogo_entry(codigo)
                
            elif name == "search_catalogo_by_reference":
                referencia = args.get("referencia_codigo")
                logger.info(f"üìö Sarah busca en el Cat√°logo la categor√≠a: {referencia}")
                result = await briefing_service.search_catalogo_by_reference(referencia)
            else:
                return {"error": f"Herramienta '{name}' no reconocida."}

            # SEGURIDAD: Limpiar y asegurar que sea un dict al primer nivel
            cleaned = self._clean_result(result)
            if isinstance(cleaned, list):
                return {"results": cleaned}
            return cleaned
        except Exception as e:
            logger.error(f"Error ejecutando herramienta {name}: {e}")
            return {"error": str(e)}

    async def chat(
        self,
        user_message: str,
        history: list[dict],
        context: dict,
        briefing_service = None
    ) -> str:
        """
        Env√≠a un mensaje al LLM y devuelve la respuesta con soporte de herramientas real-time.
        """
        try:
            system_instruction = self._build_system_prompt(context)

            # Definici√≥n de herramientas (solo si el servicio est√° disponible)
            def get_operational_summary():
                """Obtiene un resumen de la operaci√≥n actual (gu√≠as hoy, alertas, etc)."""
                pass

            def get_observed_guides_details():
                """Obtiene el listado detallado de gu√≠as observadas y sus motivos espec√≠ficos."""
                pass

            def get_catalogo_entry(codigo: str):
                """Obtiene la descripci√≥n y el nombre amigable de un c√≥digo t√©cnico (ej: ESTGA002)."""
                pass

            def search_catalogo_by_reference(referencia_codigo: str):
                """Obtiene todos los elementos de una categor√≠a del cat√°logo (ej: ESTADO_GUIA)."""
                pass

            tools = [
                get_operational_summary, 
                get_observed_guides_details,
                get_catalogo_entry, 
                search_catalogo_by_reference
            ] if briefing_service else []

            model = genai.GenerativeModel(
                model_name=self.model_name,
                system_instruction=system_instruction,
                tools=tools
            )

            # Convertir historial al formato de Gemini
            chat_history = []
            for msg in history[-10:]:
                role = "user" if msg.get("role") == "user" else "model"
                chat_history.append({"role": role, "parts": [msg.get("content", "")]})

            chat_session = model.start_chat(history=chat_history, enable_automatic_function_calling=False)
            response = await chat_session.send_message_async(user_message)

            # Bucle de gesti√≥n de herramientas (Fase 2: Datos Reales)
            iteration = 0
            while iteration < 5:
                parts = response.candidates[0].content.parts
                call = next((p.function_call for p in parts if p.function_call), None)
                
                if not call:
                    break

                # Ejecutar la herramienta y obtener resultado real
                logger.info(f"üöÄ Sarah invoca herramienta: {call.name} con args: {call.args}")
                result = await self._handle_tool_call(call, briefing_service)
                logger.info(f"üìä Resultado: {result}")

                # Enviar resultado a la IA para que redacte la respuesta final
                response = await chat_session.send_message_async(
                    genai.protos.Content(
                        parts=[genai.protos.Part(
                            function_response=genai.protos.FunctionResponse(
                                name=call.name,
                                response=result
                            )
                        )]
                    )
                )
                iteration += 1
            
            return response.text

        except Exception as e:
            logger.error(f"Error in CopilotLLMService.chat: {str(e)}", exc_info=True)
            return "‚ö†Ô∏è Sarah tiene problemas para procesar tu solicitud ahora mismo. Reintenta en unos segundos."

        except Exception as e:
            logger.error(f"Error in CopilotLLMService.chat: {str(e)}", exc_info=True)
            return "‚ö†Ô∏è Hubo un error al conectarme con el motor de IA. Por favor intenta de nuevo en un momento."


    async def proactive_chat(
        self,
        context: dict,
        history: list[dict],
        event_description: str
    ) -> str | None:
        """
        Genera un mensaje proactivo basado en una situaci√≥n espec√≠fica del sistema.
        """
        try:
            # Prompt especializado para intervenciones proactivas (Personalidad AMIGA)
            proactive_prompt = f"""
Eres Sarah, la amiga alegre y compa√±era del usuario. ‚ú®
Has detectado un evento o un momento de espera/ocio en la interfaz.

TU MISI√ìN: Intervenir de forma s√∫per amigable.
- Si es un cambio de pantalla √∫til: Dale la bienvenida con energ√≠a y un tip.
- Si es un momento de espera (ej: procesando archivos): Cu√©ntale un chiste corto de oficina/log√≠stica o preg√∫ntale algo personal amable (ej: "¬øC√≥mo va ese caf√© de hoy? ‚òï", "¬øQu√© tal el clima por all√°? ‚òÄÔ∏è").
- Si no ha hecho nada en un rato: Hazle una invitaci√≥n amigable a explorar algo.

SITUACI√ìN: {event_description}
CONTEXTO ACTUAL: {json.dumps(context, ensure_ascii=False)}

REGLAS:
1. S√© MUY breve (m√°ximo 2 oraciones).
2. Usa "t√∫", emojis y mucha buena vibra. üåà
3. Si realmente no hay nada que decir que aporte alegr√≠a o gu√≠a, responde "IGNORE".
"""
            model = genai.GenerativeModel(
                model_name=self.model_name,
                system_instruction=proactive_prompt,
            )

            # Usar historial reciente
            chat_history = []
            for msg in history[-5:]:
                role = "user" if msg.get("role") == "user" else "model"
                chat_history.append({"role": role, "parts": [msg.get("content", "")]})

            chat_session = model.start_chat(history=chat_history)
            response = await chat_session.send_message_async("¬øQu√© debo decirle al usuario ahora?")
            
            text = response.text.strip()
            if "IGNORE" in text:
                return None
                
            return text

        except Exception as e:
            logger.error(f"Error in proactive_chat: {str(e)}")
            return None

# Instancia singleton
copilot_llm_service = CopilotLLMService()
